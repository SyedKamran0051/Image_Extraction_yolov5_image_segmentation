{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "{'predictions': [{'x': 226.5, 'y': 295.0, 'width': 221.0, 'height': 324.0, 'confidence': 0.9869877696037292, 'class': 'crop', 'points': [{'x': 220.0, 'y': 456.0063442046491}, {'x': 122.0, 'y': 456.43107574196483}, {'x': 117.91698103922462, 'y': 455.0}, {'x': 115.98339111911486, 'y': 426.0}, {'x': 115.90896188088031, 'y': 134.0}, {'x': 334.0, 'y': 133.89200541334816}, {'x': 336.0549089417185, 'y': 455.0}, {'x': 220.0, 'y': 456.0063442046491}], 'image_path': 'E:\\\\segmentation_model\\\\datasets\\\\Image_extraction-2\\\\train\\\\images\\\\1064-flatalaska-4-_jpg.rf.e79d4bee51272da0f6979693851abb71.jpg', 'prediction_type': 'InstanceSegmentationModel'}, {'x': 501.0, 'y': 290.0, 'width': 224.0, 'height': 324.0, 'confidence': 0.9841165542602539, 'class': 'crop', 'points': [{'x': 578.0, 'y': 451.01058662817456}, {'x': 401.0, 'y': 451.4298414341023}, {'x': 394.94054985644397, 'y': 450.0}, {'x': 391.9887335719139, 'y': 386.0}, {'x': 391.7177047502633, 'y': 318.0}, {'x': 388.7392059324867, 'y': 274.0}, {'x': 388.5385759981084, 'y': 134.0}, {'x': 390.0, 'y': 128.98343273577294}, {'x': 608.1002239039981, 'y': 129.0}, {'x': 611.005879797512, 'y': 174.0}, {'x': 613.3588141738722, 'y': 446.0}, {'x': 609.0, 'y': 449.02595182694114}, {'x': 578.0, 'y': 451.01058662817456}], 'image_path': 'E:\\\\segmentation_model\\\\datasets\\\\Image_extraction-2\\\\train\\\\images\\\\1064-flatalaska-4-_jpg.rf.e79d4bee51272da0f6979693851abb71.jpg', 'prediction_type': 'InstanceSegmentationModel'}], 'image': {'width': '640', 'height': '640'}}\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"ldQ5fDTzNpqJryn9OGOv\")\n",
    "project = rf.workspace().project(\"image_extraction-6dog0\")\n",
    "model = project.version(3).model\n",
    "\n",
    "# infer on a local image\n",
    "print(model.predict(\"E:\\segmentation_model\\datasets\\Image_extraction-2\\\\train\\images\\\\1064-flatalaska-4-_jpg.rf.e79d4bee51272da0f6979693851abb71.jpg\").json())\n",
    "\n",
    "# infer on an image hosted elsewhere\n",
    "#print(model.predict(\"URL_OF_YOUR_IMAGE\").json())\n",
    "\n",
    "# save an image annotated with your predictions\n",
    "model.predict(\"E:\\segmentation_model\\datasets\\Image_extraction-2\\\\train\\images\\\\1064-flatalaska-4-_jpg.rf.e79d4bee51272da0f6979693851abb71.jpg\").save(\"prediction.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Perform prediction\n",
    "image_path = \"E:\\segmentation_model\\datasets\\Image_extraction-2\\\\train\\images\\\\1064-flatalaska-4-_jpg.rf.e79d4bee51272da0f6979693851abb71.jpg\"\n",
    "response = model.predict(image_path).json()\n",
    "\n",
    "# Access the predictions directly\n",
    "predictions = response['predictions']\n",
    "\n",
    "for idx, prediction in enumerate(predictions):\n",
    "    # Load the original image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Extract the points for the segmentation mask\n",
    "    points = [(p['x'], p['y']) for p in prediction['points']]\n",
    "\n",
    "    # Calculate the bounding box coordinates\n",
    "    x_min = int(min(points, key=lambda p: p[0])[0])\n",
    "    x_max = int(max(points, key=lambda p: p[0])[0])\n",
    "    y_min = int(min(points, key=lambda p: p[1])[1])\n",
    "    y_max = int(max(points, key=lambda p: p[1])[1])\n",
    "\n",
    "    # Crop the segmented image based on the bounding box coordinates\n",
    "    cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Save the segmented image\n",
    "    save_path = f\"segmented_image_{idx}.jpg\"\n",
    "    cv2.imwrite(save_path, cropped_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Perform prediction\n",
    "image_path = \"datasets\\\\Image_extraction-2\\\\valid\\\\images\\\\flat198_jpg.rf.48ce81ce13708ccd9bb08d4c4d4c96ad.jpg\"\n",
    "response = model.predict(image_path).json()\n",
    "\n",
    "# Access the predictions directly\n",
    "predictions = response['predictions']\n",
    "\n",
    "for idx, prediction in enumerate(predictions):\n",
    "    # Load the original image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Extract the points for the segmentation mask\n",
    "    points = [(p['x'], p['y']) for p in prediction['points']]\n",
    "\n",
    "    # Calculate the bounding box coordinates\n",
    "    x_min = int(min(points, key=lambda p: p[0])[0])\n",
    "    x_max = int(max(points, key=lambda p: p[0])[0])\n",
    "    y_min = int(min(points, key=lambda p: p[1])[1])\n",
    "    y_max = int(max(points, key=lambda p: p[1])[1])\n",
    "\n",
    "    # Crop the segmented image based on the bounding box coordinates\n",
    "    cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Save the segmented image with original quality\n",
    "    save_path = f\"segmented_image_{idx}.jpg\"\n",
    "    cv2.imwrite(save_path, cropped_image, [cv2.IMWRITE_JPEG_QUALITY, 100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
